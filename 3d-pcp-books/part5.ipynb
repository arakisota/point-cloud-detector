{
 "cells": [
  {
   "cell_type": "markdown",
   "id": "d2a91a7e-bb87-4038-b3b3-6660cc593849",
   "metadata": {},
   "source": [
    "# 第５章　点群からの物体認識"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "f636ad62-956a-4581-b0b0-7f4ffecb9d94",
   "metadata": {},
   "source": [
    "## 5.1 特定物体認識と一般物体認識"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "60515100-fe57-493b-85d7-d13b6da69984",
   "metadata": {},
   "source": [
    "- 狭義の物体認識\n",
    "    - 入力データに対して、ラベルを出力する識別タスクを示すことが多い\n",
    "    - 一般物体認識\n",
    "        - ラベルはあらかじめ人間が決める\n",
    "        - カテゴリレベルの認識タスク\n",
    "            - ラベルと物体が一対一対応している\n",
    "    - 特定物体認識\n",
    "        - データベースに対して入力データと一致するモデルを特定する\n",
    "        - インスタンスレベルの認識\n",
    "            - ラベルと物体が一対多の対応なっている\n",
    "  \n",
    "手順\n",
    "1. ラベルが付与された3次元データを用意する\n",
    "2. 3次元データから特徴量を抽出する\n",
    "3. 特徴量からラベルを推定する識別器を用意（学習）する\n",
    "4. 識別対象物体の3次元データから特徴量を抽出する\n",
    "5. 識別器を用いてラベルを推定する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "id": "2ce8682c-14af-4fac-aa07-3ea8080cbe0e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#手順1：ラベルが付与された3次元データを用意する\n",
    "import os\n",
    "\n",
    "dirname = \"rgbd-dataset\"\n",
    "classes = [\"apple\", \"banana\", \"camera\"]\n",
    "url = \"https://rgbd-dataset.cs.washington.edu/dataset/rgbd-dataset_pcd_ascii/\"\n",
    "#有名な3次元点群データセットRGB-D Object Datasetの一部をダウンロードする\n",
    "for i in range(len(classes)):\n",
    "    if not os.path.exists(dirname + \"/\" + classes[i]):\n",
    "        os.system(\"wget \" + url + classes[i] + \"_1.tar\")\n",
    "        os.system(\"tar xvf \"+ classes[i] + \"_1.tar\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 5,
   "id": "aa760a7b-67ff-4179-b38e-a41260ec43dc",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "手順2:3次元データから特徴量を抽出する\n",
    "手順3:特徴量からラベルを推定する識別器を用意（学習）する -> 今回は簡略化して、k=1のk最近傍法を用いる。\n",
    "すなわち認識対象物体の特徴量とデータベース内の全物体の特徴量との類似度を計算し、最も類似度の高いデータベース物体のラベルを出力するという仕組み\n",
    "手順4:識別対象物体の3次元データから特徴量を抽出する\n",
    "\"\"\"\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "\n",
    "\"\"\"\n",
    "今回は点群データ全体で一つの物体として認識するために、点群データ全体から大域特徴量を抽出する必要がある。\n",
    "そのため、 FPTHで33次元の特徴量を計算して、その総和をとって、13行目で特徴量のノルムを1に正規化して返す。\n",
    "\"\"\"\n",
    "def extract_fpth(filename):\n",
    "    print(\" \", filename)\n",
    "    #点群の読み込み\n",
    "    pcd = o3d.io.read_point_cloud(filename)\n",
    "    #ボクセルのダウンサンプリング\n",
    "    pcd = pcd.voxel_down_sample(0.01)\n",
    "    #法線ベクトルの推定\n",
    "    pcd.estimate_normals(\n",
    "        search_param = o3d.geometry.KDTreeSearchParamHybrid(radius=0.02, max_nn=10))\n",
    "    #FPTH特徴量を抽出\n",
    "    fpth = o3d.pipelines.registration.compute_fpfh_feature(pcd, \n",
    "                                                          search_param = o3d.geometry.KDTreeSearchParamHybrid(radius=0.03, max_nn=100))\n",
    "    #33次元のFPTHの特徴量の総和を計算\n",
    "    sum_fpth = np.sum(np.array(fpth.data), 1)\n",
    "    #最後に1に正規化して返す\n",
    "    return(sum_fpth / np.linalg.norm(sum_fpth))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c54b3fd5-a478-4801-90de-4709d20333a2",
   "metadata": {},
   "source": [
    "#### データについて\n",
    "apple, banana, cameraの3個の物体の点群データに対して、それぞれ方位角と3パターンの高度を変化させて撮影したデータ600個以上入っている  \n",
    "appe_1_x_y.pcdだったらxが高度角のレベルでyが方位角のレベルを示している"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 6,
   "id": "41297080-b0ec-4d37-b196-5dbba2e0118e",
   "metadata": {
    "collapsed": true,
    "jupyter": {
     "outputs_hidden": true
    },
    "tags": []
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Extracting train features in apple...\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_1.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_2.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_3.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_4.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_5.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_6.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_7.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_8.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_9.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_10.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_11.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_12.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_13.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_14.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_15.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_16.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_17.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_18.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_19.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_20.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_21.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_22.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_23.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_24.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_25.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_26.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_27.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_28.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_29.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_30.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_31.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_32.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_33.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_34.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_35.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_36.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_37.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_38.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_39.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_40.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_41.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_42.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_43.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_44.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_45.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_46.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_47.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_48.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_49.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_50.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_51.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_52.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_53.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_54.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_55.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_56.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_57.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_58.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_59.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_60.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_61.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_62.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_63.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_64.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_65.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_66.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_67.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_68.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_69.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_70.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_71.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_72.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_73.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_74.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_75.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_76.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_77.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_78.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_79.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_80.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_81.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_82.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_83.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_84.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_85.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_86.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_87.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_88.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_89.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_90.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_91.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_92.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_93.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_94.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_95.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_96.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_97.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_98.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_99.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_1_100.pcd\n",
      "Exrtacting test features in apple...\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_1.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_2.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_3.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_4.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_5.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_6.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_7.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_8.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_9.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_10.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_11.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_12.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_13.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_14.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_15.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_16.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_17.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_18.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_19.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_20.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_21.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_22.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_23.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_24.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_25.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_26.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_27.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_28.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_29.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_30.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_31.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_32.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_33.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_34.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_35.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_36.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_37.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_38.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_39.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_40.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_41.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_42.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_43.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_44.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_45.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_46.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_47.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_48.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_49.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_50.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_51.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_52.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_53.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_54.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_55.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_56.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_57.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_58.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_59.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_60.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_61.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_62.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_63.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_64.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_65.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_66.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_67.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_68.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_69.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_70.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_71.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_72.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_73.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_74.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_75.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_76.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_77.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_78.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_79.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_80.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_81.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_82.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_83.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_84.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_85.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_86.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_87.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_88.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_89.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_90.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_91.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_92.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_93.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_94.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_95.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_96.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_97.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_98.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_99.pcd\n",
      "  rgbd-dataset/apple/apple_1/apple_1_4_100.pcd\n",
      "Extracting train features in banana...\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_1.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_2.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_3.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_4.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_5.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_6.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_7.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_8.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_9.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_10.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_11.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_12.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_13.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_14.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_15.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_16.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_17.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_18.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_19.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_20.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_21.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_22.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_23.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_24.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_25.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_26.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_27.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_28.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_29.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_30.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_31.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_32.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_33.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_34.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_35.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_36.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_37.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_38.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_39.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_40.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_41.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_42.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_43.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_44.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_45.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_46.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_47.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_48.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_49.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_50.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_51.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_52.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_53.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_54.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_55.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_56.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_57.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_58.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_59.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_60.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_61.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_62.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_63.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_64.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_65.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_66.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_67.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_68.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_69.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_70.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_71.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_72.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_73.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_74.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_75.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_76.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_77.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_78.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_79.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_80.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_81.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_82.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_83.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_84.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_85.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_86.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_87.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_88.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_89.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_90.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_91.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_92.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_93.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_94.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_95.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_96.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_97.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_98.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_99.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_1_100.pcd\n",
      "Exrtacting test features in banana...\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_1.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_2.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_3.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_4.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_5.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_6.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_7.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_8.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_9.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_10.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_11.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_12.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_13.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_14.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_15.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_16.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_17.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_18.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_19.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_20.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_21.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_22.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_23.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_24.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_25.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_26.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_27.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_28.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_29.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_30.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_31.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_32.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_33.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_34.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_35.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_36.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_37.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_38.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_39.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_40.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_41.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_42.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_43.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_44.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_45.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_46.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_47.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_48.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_49.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_50.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_51.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_52.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_53.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_54.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_55.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_56.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_57.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_58.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_59.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_60.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_61.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_62.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_63.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_64.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_65.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_66.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_67.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_68.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_69.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_70.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_71.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_72.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_73.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_74.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_75.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_76.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_77.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_78.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_79.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_80.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_81.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_82.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_83.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_84.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_85.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_86.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_87.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_88.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_89.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_90.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_91.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_92.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_93.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_94.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_95.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_96.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_97.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_98.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_99.pcd\n",
      "  rgbd-dataset/banana/banana_1/banana_1_4_100.pcd\n",
      "Extracting train features in camera...\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_1.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_2.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_3.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_4.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_5.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_6.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_7.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_8.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_9.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_10.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_11.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_12.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_13.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_14.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_15.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_16.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_17.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_18.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_19.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_20.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_21.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_22.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_23.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_24.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_25.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_26.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_27.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_28.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_29.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_30.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_31.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_32.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_33.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_34.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_35.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_36.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_37.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_38.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_39.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_40.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_41.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_42.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_43.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_44.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_45.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_46.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_47.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_48.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_49.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_50.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_51.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_52.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_53.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_54.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_55.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_56.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_57.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_58.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_59.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_60.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_61.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_62.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_63.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_64.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_65.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_66.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_67.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_68.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_69.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_70.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_71.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_72.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_73.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_74.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_75.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_76.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_77.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_78.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_79.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_80.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_81.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_82.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_83.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_84.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_85.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_86.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_87.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_88.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_89.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_90.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_91.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_92.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_93.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_94.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_95.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_96.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_97.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_98.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_99.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_1_100.pcd\n",
      "Exrtacting test features in camera...\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_1.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_2.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_3.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_4.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_5.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_6.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_7.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_8.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_9.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_10.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_11.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_12.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_13.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_14.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_15.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_16.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_17.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_18.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_19.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_20.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_21.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_22.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_23.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_24.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_25.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_26.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_27.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_28.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_29.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_30.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_31.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_32.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_33.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_34.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_35.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_36.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_37.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_38.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_39.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_40.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_41.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_42.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_43.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_44.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_45.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_46.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_47.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_48.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_49.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_50.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_51.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_52.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_53.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_54.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_55.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_56.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_57.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_58.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_59.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_60.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_61.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_62.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_63.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_64.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_65.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_66.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_67.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_68.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_69.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_70.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_71.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_72.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_73.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_74.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_75.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_76.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_77.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_78.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_79.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_80.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_81.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_82.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_83.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_84.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_85.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_86.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_87.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_88.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_89.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_90.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_91.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_92.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_93.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_94.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_95.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_96.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_97.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_98.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_99.pcd\n",
      "  rgbd-dataset/camera/camera_1/camera_1_4_100.pcd\n"
     ]
    }
   ],
   "source": [
    "#100個を学習データ、別の100個をテキストデータとして読み込んで特徴量を抽出している\n",
    "nsamp = 100\n",
    "feat_train = np.zeros((len(classes), nsamp, 33))\n",
    "feat_test = np.zeros((len(classes), nsamp, 33))\n",
    "\n",
    "for i in range(len(classes)):\n",
    "    print(\"Extracting train features in \" + classes[i] + \"...\")\n",
    "    for n in range(nsamp):\n",
    "        filename = dirname + \"/\" + classes[i] + \"/\" + classes[i] + \"_1/\" + classes[i] + \"_1_1_\" + str(n+1) + \".pcd\"\n",
    "        #学習データの特徴量を格納\n",
    "        feat_train[i, n] = extract_fpth(filename)\n",
    "    print(\"Exrtacting test features in \" + classes[i] + \"...\")\n",
    "    for n in range(nsamp):\n",
    "        filename = dirname + \"/\" + classes[i] + \"/\" + classes[i] + \"_1/\" + classes[i] + \"_1_4_\" + str(n+1) + \".pcd\"\n",
    "        #学習データの特徴量を格納        \n",
    "        feat_test[i, n] = extract_fpth(filename)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 7,
   "id": "b67be9fa-cfe0-484d-88a8-1c20d26d5c7e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Accuracy of  apple : 98.0 %\n",
      "Accuracy of  banana : 89.0 %\n",
      "Accuracy of  camera : 83.0 %\n"
     ]
    }
   ],
   "source": [
    "\"\"\"\n",
    "手順5:識別器を用いてラベルを推定する -> k最近傍法を用いる\n",
    "2つの点群データの類似度としてベクトルの内積を用いる\n",
    "\"\"\"\n",
    "for i in range(len(classes)):\n",
    "    max_sim = np.zeros((3, nsamp))\n",
    "    for j in range(len(classes)):\n",
    "        sim = np.dot(feat_test[i], feat_train[j].transpose())\n",
    "        #j番目の物体の全データの中で最も近いデータとの類似度が格納される→これが最も高いクラスとして推定されたラベルとなる\n",
    "        max_sim[j] = np.max(sim, 1)\n",
    "    #本来のラベルと一致している数を計算\n",
    "    correct_num = (np.argmax(max_sim, 0) == i).sum()\n",
    "    print(\"Accuracy of \", classes[i], \":\", correct_num*100/nsamp, \"%\")"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "aa54e790-191c-4bc5-9669-53c2ba299fc1",
   "metadata": {},
   "source": [
    "### この結果からわかること\n",
    "比較的容易なタスクである特定物体認識は同一の物体でも環境や撮影状況が異なるだけで精度が変化する  \n",
    "  \n",
    "精度が変化する要因\n",
    "- 照明環境の違いによる色の変化\n",
    "- センサから物体までの距離の違いによる解像度の変化\n",
    "- センサノイズ\n",
    "- 前景に存在する障害物による隠れ（オクルージョン）\n",
    "- 物体の姿勢変化\n",
    "    - 今回は特にこれが影響した\n",
    "    - FPTHを使用したため、回転不変の特徴量なはず\n",
    "    - だが今回は、単一視点から撮影したデータであるため、裏側が見えず2.5次元データになっていた\n",
    "        - そのため点群データの存在する物体の表面が変化して、データが変化してしまった"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "a550f38d-6489-43c6-9bad-0fc0acb50bab",
   "metadata": {},
   "source": [
    "#### 一般物体認識\n",
    "- ラベルと物体が一対多の対応になっている\n",
    "    - カテゴリ内の物体に共通する、より抽象的な特徴を捉えることがカギとなる\n",
    "    - ただ最近の深層学習はタスクに合わせた特徴抽出を学習するため、あまり特定物体認識と一般物体認識の区別があまりない\n",
    "  \n",
    "今回はそのうち2例を紹介する  \n",
    "- ある未知の3次元物体データが与えられたとき、形状が類似した3次元物体データをデータベースから検索し、類似度の高い順に検索結果を出力するタスク\n",
    "    - 入力のカテゴリと一致した場合は正解\n",
    "    - 精度と再現率を算出\n",
    "    - この方法をBag-Of-Features(B0F)という\n",
    "  \n",
    "BoFの手順\n",
    "1. データベース内の物体データから点をサンプリングする\n",
    "2. 各点における局所特徴量を抽出する\n",
    "    - SIFT(Scale-Invariant Feature Transform)特徴量など\n",
    "3. 全ての局所特徴量に対して、k-meansクラスタリングを行う\n",
    "4. 各クラスタ中心(visual word)の集合をvisual codebookとする\n",
    "5. 入力データから点をサンプリング\n",
    "6. 各点における局所特徴量を抽出し、最近傍のvisual wordに割り当てる\n",
    "7. 各visual wordに割り当てられた点の個数を数え上げ、ヒストグラムを作る\n",
    "  \n",
    "大渕らの研究 \n",
    "- 主成分分析を用いて三次元モデルの主軸を求め、姿勢を正規化した上で複数視点からの画像をレンダリングし、それらの画像からSIFT特徴量を抽出する\n",
    "    - そして、異なる二つの物体データのBoF特徴量の類似度をKLダイバージェンスによって求める\n",
    "- ヒストグラム類似度としては、カイ２条距離などで類似度を求める\n",
    "  \n",
    "Laiらの研究\n",
    "- 木構造で徐々にカテゴリからインスタンス、さらに視点、姿勢と絞っていくことで特定する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "8d2b71d9-dc9c-4c23-8530-eab5b9b4c3d7",
   "metadata": {},
   "source": [
    "## 5.2 特定物体の姿勢推定\n",
    "- 異なる視点で撮影された点群を入力として、これらを貼り合わせる\n",
    "    - 特徴点マッチング\n",
    "        - 入力の二つの点群を貼り合わせるために変換行列を求めること\n",
    "        - 変換行列は4×4の同時変換行列T = [R, t ; 0, 1]で表されることが一般的\n",
    "        - 特徴点マッチングは初期位置が近いことを前提としていないため、より一般的なシーンで利用できる利点がある\n",
    "            - ICPアルゴリズムは初期位置が近いことを前提\n",
    "        - より精度が求められる状況下では、特徴点マッチングで得られた位置姿勢を初期値として、ICPアルゴリズムを適用する\n",
    "- ソースとターゲットのよく似た部分を部分的な領域を見つけ出して、その情報をもとに姿勢を計算する\n",
    "    - 部分的な類似性を計算するので、効率的な姿勢計算が可能になる\n",
    "  \n",
    "手順\n",
    "1. 特徴点検出\n",
    "    - ISS\n",
    "    - 等間隔サンプリング\n",
    "2. 特徴量記述\n",
    "    - 特徴点に対してその特徴点らしさを表現する情報（アイデンティティ）を付与する処理\n",
    "    - 特徴点周りの形状をもとに計算した多次元ベクトルを特徴量とすることが一般的\n",
    "3. 対応点探索\n",
    "    - 物体モデルと入力シーン間で物理的に同一の地点を指す座標同士の対応を得るようにしたい\n",
    "    - 両特徴量間のノルムが最も小さい特徴点のペアを対応点にする\n",
    "        - 誤った点に対応した時\n",
    "        1. 特徴量間のノルムに閾値を設ける\n",
    "            - だが点群にはセンサノイズやオクルージョンによる部分的な欠損が生じるため、閾値設定が難しい\n",
    "        2. 双方向チェック\n",
    "            - ソースからターゲットへのベストマッチ、ターゲットからソースへのベストマッチが一致すれば対応点としてみなす\n",
    "        3. Ratio Test\n",
    "            - 最近傍のノルムが他と比べて際立って小さいかどうかを調べる\n",
    "            - 第一と第二で比を取って、閾値以下の場合に対応点とする\n",
    "4. 姿勢計算\n",
    "    - RANSAC(RANdom SAmple Consensus)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "id": "81390ccb-270f-4664-b6a8-3f9173134524",
   "metadata": {},
   "outputs": [],
   "source": [
    "#特徴点検出\n",
    "#今回は等間隔サンプリング：Voxel Grid Filterを使用\n",
    "\n",
    "#特徴量記述\n",
    "#今回はFPTH特徴量を利用する\n",
    "\n",
    "import copy\n",
    "\n",
    "path = \"../3rdparty/Open3D/examples/test_data/ICP/\"\n",
    "source = o3d.io.read_point_cloud(path+\"cloud_bin_0.pcd\")\n",
    "target = o3d.io.read_point_cloud(path+\"cloud_bin_1.pcd\")\n",
    "\n",
    "source.paint_uniform_color([0.5, 0.5, 1])\n",
    "target.paint_uniform_color([1.0, 0.5, 0.5])\n",
    "initial_trans = np.identity(4)\n",
    "initial_trans[0, 3] = -3.0\n",
    "\n",
    "\"\"\"\n",
    "点群を画面表示するための関数\n",
    "source : 点群をリストとして渡す\n",
    "target : 点群をリストとして渡す\n",
    "transformation : 姿勢変換のための変換行列\n",
    "\"\"\"\n",
    "def draw_registration_result(source, target, transformation):\n",
    "    pcds = list()\n",
    "    for s in source:\n",
    "        temp = copy.deepcopy(s)\n",
    "        pcds.append(temp.transform(transformation))\n",
    "    pcds += target\n",
    "    o3d.visualization.draw_geometries(pcds, zoom=0.3199,\n",
    "                                     front = [0.024, -0.225, -0.073],\n",
    "                                     lookat = [0.488, 1.722, 1.556],\n",
    "                                     up = [0.047, -0.972, 0.226])\n",
    "    \n",
    "draw_registration_result([source], [target], initial_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "id": "6b485dba-6179-4a7d-b711-1f50c8a6e92a",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "二つの点群から、特徴点を検出し、特徴量を計算する\n",
    "pcd : 点群データ\n",
    "voxel_size : Voxel Grid Filterのボクセルサイズ→検出する特徴点の間隔\n",
    "\"\"\"\n",
    "def keypoint_and_future_extraction(pcd, voxel_size):\n",
    "    #間引いた点群を特徴点とする\n",
    "    keypoints = pcd.voxel_down_sample(voxel_size)\n",
    "    \n",
    "    \"\"\"法線を計算\"\"\"\n",
    "    viewpoint = np.array([0., 0., 0.], dtype='float64')\n",
    "    #間引いたデータの倍の半径を指定\n",
    "    radius_normal = 2.0 * voxel_size\n",
    "    #半径内で最大30点を使って計算する\n",
    "    keypoints.estimate_normals(\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_normal, max_nn=30))\n",
    "    #原点に法線ベクトルが向くように法線方向に反転処理を適用している\n",
    "    keypoints.orient_normals_towards_camera_location(viewpoint)\n",
    "    \n",
    "    \"\"\"特徴量を計算\"\"\"\n",
    "    #特徴点の間隔の5倍の距離を限度とした球領域とする\n",
    "    radius_feature = 5.0 * voxel_size\n",
    "    #球領域に含まれる点の近いものから順に最大100点を選択する\n",
    "    feature = o3d.pipelines.registration.compute_fpfh_feature(\n",
    "        keypoints,\n",
    "        o3d.geometry.KDTreeSearchParamHybrid(radius=radius_feature, max_nn=100))\n",
    "    return keypoints, feature\n",
    "\n",
    "voxel_size = 0.1\n",
    "s_kp, s_feature = keypoint_and_future_extraction(source, voxel_size)\n",
    "t_kp, t_feature = keypoint_and_future_extraction(target, voxel_size)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "id": "1c90ee71-b7ed-4f9b-8c22-c161f7e76113",
   "metadata": {},
   "outputs": [],
   "source": [
    "s_kp.paint_uniform_color([0, 1, 0])\n",
    "t_kp.paint_uniform_color([0, 1, 0])\n",
    "draw_registration_result([source, s_kp], [target, t_kp], initial_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 11,
   "id": "58f6ac23-e432-4159-b175-f28db907fec6",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "対応点セットの数 :  270\n"
     ]
    }
   ],
   "source": [
    "#対応点探索 : Ratio Test\n",
    "#特徴量ベクトルを取り出して、(n, 33)行列を作成\n",
    "np_s_feature = s_feature.data.T\n",
    "np_t_feature = t_feature.data.T\n",
    "\n",
    "#corrsは対応点のセットを保存するための変数。ソース、ターゲット双方の特徴点のインデックスを保持する\n",
    "corrs = o3d.utility.Vector2iVector()\n",
    "threshold = 0.9\n",
    "#ソースの特定の特徴点の特徴量と、ターゲットの特徴量のL2ノルムを計算する。\n",
    "#ノルムが小さいものから１位と2位の比を計算して、threshold以下であれば、正しい対応点セットとみなして、ソース、ターゲットのインデックスを保存する\n",
    "for i, feat in enumerate(np_s_feature):\n",
    "    distance = np.linalg.norm(np_t_feature - feat, axis=1)\n",
    "    nearest_idx = np.argmin(distance)\n",
    "    dist_order = np.argsort(distance)\n",
    "    ratio = distance[dist_order[0]] / distance[dist_order[1]]\n",
    "    if ratio < threshold:\n",
    "        corr = np.array([[i], [nearest_idx]], np.int32)\n",
    "        corrs.append(corr)\n",
    "    \n",
    "print(\"対応点セットの数 : \", (len(corrs)))"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "d7d1c09f-2dde-4374-a0e2-620a9278d549",
   "metadata": {},
   "source": [
    "#### 姿勢計算\n",
    "- 対応点探索によって得られた対応点を使って、ソースをターゲットに位置合わせする変換を推定する\n",
    "    - ただし、対応点セットには誤りを含む場合があることに注意する\n",
    "    - ここで頑健な推定法として、有名なRANSAC(RANdom SAmple Consensus)を利用する\n",
    "  \n",
    "#### RANSAC\n",
    "- 点群処理以外にも広く使われている外れ値に対して、頑健な推定法の一種\n",
    "- 外れ値が含まれた観測値から、その影響を抑えつつ、モデルパラメータを推定する\n",
    "  \n",
    "方法\n",
    "1. サンプリング\n",
    "    - ランダムに数個の計測点を選択し、モデルパラメータを推定する\n",
    "    - サンプリングの処理の時に、外れ値を除いたデータのみを引き当てることを期待している\n",
    "2. 評価\n",
    "    - 得られたモデルパラメータの良さを評価する"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 16,
   "id": "8976a2ff-429a-4f23-8a87-23318fd4a8e9",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "Open3Dのvisualizerで表示可能な直線群を作成する\n",
    "\"\"\"\n",
    "def create_lineset_from_correspondences(corrs_set, pcd1, pcd2, \n",
    "                                       transformation=np.identity(4)):\n",
    "    pcd1_temp = copy.deepcopy(pcd1)\n",
    "    pcd1_temp.transform(transformation)\n",
    "    corrs = np.asarray(corrs_set)\n",
    "    np_points1 = np.array(pcd1_temp.points)\n",
    "    np_points2 = np.array(pcd2.points)\n",
    "    points = list()\n",
    "    lines = list()\n",
    "    \n",
    "    for i in range(corrs.shape[0]):\n",
    "        points.append(np_points1[corrs[i, 0]])\n",
    "        points.append(np_points2[corrs[i, 1]])\n",
    "        lines.append([2*i, (2*i)+1])\n",
    "        \n",
    "    colors = [np.random.rand(3) for i in range(len(lines))]\n",
    "    line_set = o3d.geometry.LineSet(\n",
    "    points=o3d.utility.Vector3dVector(points),\n",
    "    lines=o3d.utility.Vector2iVector(lines)\n",
    "    )\n",
    "    line_set.colors = o3d.utility.Vector3dVector(colors)\n",
    "    return line_set\n",
    "\n",
    "line_set = create_lineset_from_correspondences(corrs, s_kp, t_kp,\n",
    "                                              initial_trans)\n",
    "draw_registration_result([source, s_kp],\n",
    "                        [target, t_kp, line_set],\n",
    "                        initial_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 17,
   "id": "e030d420-ba86-44f7-93bd-3e67b7377441",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "外れ値を含む対応点を使って、姿勢を計算したため、ずれが目立つ\n",
    "\"\"\"\n",
    "#全ての点を使って、姿勢計算をする\n",
    "#二つの対応の取れた点群の二乗誤差を最小化する変換行列を算出する。スケーリングを含めた変換の推定が可能。ここでFalseはスケーリングが1ということ\n",
    "trans_ptp = o3d.pipelines.registration.TransformationEstimationPointToPoint(False)\n",
    "#変換行列を算出\n",
    "trans_all = trans_ptp.compute_transformation(s_kp, t_kp, corrs)\n",
    "draw_registration_result([source], [target], trans_all)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "74aeafbd-a68d-42d9-b1cc-e0abc1a97303",
   "metadata": {},
   "source": [
    "#### RANSACの実装\n",
    "1. サンプリング ： 全ての対応点からあらかじめ決めておいた個数の対応点を選択し、変換行列を計算する。\n",
    "- TransformationEstimationPointToPoint()を利用する\n",
    "2. 評価 ： 得られた変換行列の妥当性を評価する。ソース側の点群を変換行列によって姿勢変換し、ターゲット側の点群との距離を計算する。\n",
    "- この値があらかじめ決めておいた、マージンより小さい場合は、その対応点をインライアとして判定する。またインライアの対応点一点あたりの距離の平均値を計算する。この値が小さいほど、良い変換行列ということ。\n",
    "  \n",
    "1,2を繰り返して、最も良い変換行列を最終結果とする\n",
    "  \n",
    "引数の説明\n",
    "- s_kp, t_kp, corrs : RANSACのために必要な材料\n",
    "    - それぞれソース側の特徴点、ターゲット側の特徴点、対応点探索によって得られた対応点のインデックスのリスト\n",
    "- distance_threshold　: インライアと判定するマージンの閾値\n",
    "- ransac_n : 姿勢変換行列の計算のためにサンプリングする対応点の個数\n",
    "- checkers : 枝切り処理に使われる条件\n",
    "    - サンプリングと評価の間に簡単な条件を設定することでによって、すでに調べる必要のない（外れ値を含んだ）サンプルを除外すること。そしてこれによって高速化を図る\n",
    "    - EdgeLength : サンプリングした対応点の配置の関係性を評価する\n",
    "        - 片方の点群内での対応転換の距離のこと\n",
    "        - ソースないで2点選び、同様にターゲット内で２点選び、それぞれの２点の対応点の距離を比較した時にどれくらい類似するかで枝切りする\n",
    "            - 同一の点であれば、距離が似たような値になるはず\n",
    "    - Distance : 変換行列によって、サンプリングした対応点(ransac_n点)を変換し、距離が近いかどうかを判定する\n",
    "        - 近ければ、有望な変換行列としてみなす\n",
    " - criteria : RANSACの終了条件を指定する\n",
    "     - 第一引数 : 試行回数の最大数\n",
    "     - 第ニ引数 : 早期終了の時に使う引数\n",
    "  \n",
    "resultの要素とその内容\n",
    "- correspondence_set : インライアと判定された対応点のインデックスのリスト\n",
    "- fitness : インライア数/対応点数の値、大きいほどいい\n",
    "- inlier_rmse : インライアの平均二乗誤差、小さいほどよい\n",
    "- transformation : 4×4の変換行列"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 19,
   "id": "286161c1-e862-4f56-95f4-d2bd09e3c4fa",
   "metadata": {},
   "outputs": [],
   "source": [
    "distance_threshold = voxel_size * 1.5\n",
    "result = o3d.pipelines.registration.registration_ransac_based_on_correspondence(\n",
    "    s_kp, t_kp, corrs,\n",
    "    distance_threshold,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "    ransac_n = 3,\n",
    "    checkers = [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "    ],\n",
    "    criteria = o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 21,
   "id": "6e399389-4148-4356-9f7a-01a97a1544af",
   "metadata": {},
   "outputs": [],
   "source": [
    "#対応点の可視化\n",
    "line_set = create_lineset_from_correspondences(result.correspondence_set, \n",
    "                                              s_kp, t_kp, initial_trans)\n",
    "draw_registration_result([source, s_kp],\n",
    "                        [target, t_kp, line_set],\n",
    "                        initial_trans)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 22,
   "id": "6cbe6f0a-00d2-49c6-9016-aa42f952c4b9",
   "metadata": {},
   "outputs": [],
   "source": [
    "#実際にマッチングして可視化\n",
    "draw_registration_result([source], [target], result.transformation)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 24,
   "id": "4f413838-2841-43a9-b24a-3dfaf5050a6c",
   "metadata": {},
   "outputs": [],
   "source": [
    "#Open3Dには、対応点探索とRANSACによる姿勢計算をまとめて実行する方法がある\n",
    "distance_threshold = voxel_size * 1.5\n",
    "result = o3d.pipelines.registration.registration_ransac_based_on_feature_matching(\n",
    "    s_kp, t_kp, s_feature, t_feature, True, \n",
    "    distance_threshold,\n",
    "    o3d.pipelines.registration.TransformationEstimationPointToPoint(False),\n",
    "    ransac_n = 3,\n",
    "    checkers = [\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnEdgeLength(0.9),\n",
    "            o3d.pipelines.registration.CorrespondenceCheckerBasedOnDistance(distance_threshold)\n",
    "    ],\n",
    "    criteria = o3d.pipelines.registration.RANSACConvergenceCriteria(100000, 0.999)\n",
    "    )"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 25,
   "id": "ce69c450-31b8-4666-b194-1097f4410036",
   "metadata": {},
   "outputs": [],
   "source": [
    "#実際にマッチングして可視化\n",
    "draw_registration_result([source], [target], result.transformation)"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "c9ade042-9339-4639-abee-abe6440f8953",
   "metadata": {},
   "source": [
    "## 5.3 一般物体の姿勢推定"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "881b5c20-4f7d-43a3-9839-fa9dee96d1d9",
   "metadata": {},
   "source": [
    "#### 割愛する"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "91d9a979-3056-4a7a-b7de-c7cdcd401bbe",
   "metadata": {},
   "source": [
    "## 5.4 プリミティブ検出"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "2067a718-5f1c-40a5-b951-0e009b5aec02",
   "metadata": {},
   "source": [
    "- プリミティブ検出\n",
    "    - 平面や球などの単純な図形を検出する処理\n",
    "    - 　机の上に並べた対象物を検出したい場合、事前に平面を検出してから、その部分の点群を削除してしまえば、ここの物体を簡単に単離（検出）できる\n",
    "    - シーン理解のためのかなり強力な前処理として利用できる"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 31,
   "id": "faac61b2-812d-4f9e-b730-c28ff3fa4f90",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Plane equation : 0.02x + 0.74y + 0.67z + -0.31 = 0\n"
     ]
    }
   ],
   "source": [
    "#平面の検出\n",
    "\"\"\"\n",
    "segment_plane()ではRANSACによる平面検出を実行している\n",
    "RANSACによって、平面の方程式ax + by + cz + d = 0で表す。そのため、モデルパラメータはa, b, c, dとなる。\n",
    "考え方は、今までと同様で最も点群に近い平面を見つけるということ。そのため、あるランダムに取った3点の平面とその他の点群との距離を計算して、インライアの閾値をクリアすればカウントする。　\n",
    "評価方法は、インライア点数/総点数でインライアの平均誤差が最小になるものを採用する。\n",
    "\n",
    "引数\n",
    "distance_theshold : RANSACの評価処理で利用される。平面のインライアとして判定するための距離の閾値。単位はメートル\n",
    "ransac_n : RANSACのサンプリング処理で利用される。この点数から平面のパラメータを計算する。\n",
    "num_iterations : RANSACのサンプリング処理と評価処理の繰り返し回数\n",
    "\"\"\"\n",
    "\n",
    "pcd = o3d.io.read_point_cloud(\"../data/tabletop_scene.ply\")\n",
    "o3d.visualization.draw_geometries([pcd])\n",
    "#plane_model : 平面パラメータ\n",
    "#inliers : 元の点群における、平面上の点のインデックスのリスト\n",
    "plane_model, inliers = pcd.segment_plane(distance_threshold=0.005,\n",
    "                                        ransac_n=3,\n",
    "                                        num_iterations=500)\n",
    "\n",
    "[a, b, c, d] = plane_model\n",
    "print(f\"Plane equation : {a:.2f}x + {b:.2f}y + {c:.2f}z + {d:.2f} = 0\") \n",
    "\n",
    "#点群を平面のものとそれ以外で色分けする\n",
    "plane_cloud = pcd.select_by_index(inliers)\n",
    "plane_cloud.paint_uniform_color([1.0, 0, 0])\n",
    "outlier_cloud = pcd.select_by_index(inliers, invert=True)\n",
    "o3d.visualization.draw_geometries([plane_cloud, outlier_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 42,
   "id": "2ac6ae67-8da9-497f-9210-7a7ebc4d590d",
   "metadata": {},
   "outputs": [],
   "source": [
    "#球の検出(Open3Dには実装されていない)\n",
    "import numpy as np\n",
    "\"\"\"\n",
    "球の方程式は(x-a)^2 + (y-b)^2 + (z-c)^2 = r^2となるから、a, b, c, dの4つがパラメータになる。\n",
    "球の方程式に4つの３次元点群を入力してあげて、連立方程式を解く。\n",
    "評価方法は、平面の検出と同様に、インライア点数/総点数でインライアの平均誤差が最小になるものを採用する。\n",
    "\"\"\"\n",
    "def ComputerSphereCoefficient(p0, p1, p2, p3):\n",
    "    A = np.array([p0-p3, p1-p3, p2-p3])\n",
    "    p3_2 = np.dot(p3, p3)\n",
    "    b = np.array([(np.dot(p0, p0) - p3_2) / 2,\n",
    "                  (np.dot(p1, p1) - p3_2) / 2,\n",
    "                  (np.dot(p2, p2) - p3_2) / 2])\n",
    "    coeff = np.zeros(3)\n",
    "    try:\n",
    "        #連立方程式を解く\n",
    "        ans = np.linalg.solve(A, b)\n",
    "    except:\n",
    "        print(\"Error!! Matrix rank is\", np.linalg.matrix_rank(A))\n",
    "        print(\"Return\", coeff)\n",
    "        pass\n",
    "    else:\n",
    "        tmp = p0 - ans\n",
    "        r = np.sqrt(np.dot(tmp, tmp))\n",
    "        #球の方程式のパラメータa, b, c, rが格納される\n",
    "        coeff = np.append(ans, r)\n",
    "        \n",
    "    return coeff"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 43,
   "id": "8346b29e-ef5b-4fe1-8650-5a5a32e85cd4",
   "metadata": {},
   "outputs": [],
   "source": [
    "\"\"\"\n",
    "球の中心とある点群との距離を計算して、半径から閾値に収まるものをインライアとしてカウントする。\n",
    "pcd : 入力点群\n",
    "coeff : 球のパラメータ\n",
    "distance_th : 距離の閾値\n",
    "fitness : 出力、モデルである球の当てはめのよさ　\n",
    "inlier_dist : インライアの平均誤差\n",
    "inliers : インライア点群のインデックスリスト\n",
    "\"\"\"\n",
    "def EvaluateSphereCoefficient(pcd, coeff, distance_th=0.01):\n",
    "    fitness = 0\n",
    "    inlier_dist = 0\n",
    "    inliers = None\n",
    "    \n",
    "    #点群中の全ての点に対する球面との距離を一気に計算（ブロードキャスト）\n",
    "    dist = np.abs(np.linalg.norm(pcd - coeff[:3], axis=1) - coeff[3])\n",
    "    n_inlier = np.sum(dist < distance_th)\n",
    "    if n_inlier != 0:\n",
    "        fitness = n_inlier / pcd.shape[0]\n",
    "        inlire_dost = np.sum((dist < distance_th) * dist) / n_inlier\n",
    "        inliers = np.where(dist < distance_th)[0]\n",
    "        \n",
    "    return fitness, inlier_dist, inliers"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 44,
   "id": "ff3fee27-4f29-48ea-b27e-c7949397c78e",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Update: Fitness = 0.3306, Inlier_dist = 0.0000\n",
      "Update: Fitness = 0.3320, Inlier_dist = 0.0000\n",
      "Sphere equation:  (x - 0.12)^2 + (y - 0.07)^2 + (z - 0.34)^2) = 0.04^2\n"
     ]
    }
   ],
   "source": [
    "#繰り返し演算の実装（より良いパラメータを探す）\n",
    "pcd = outlier_cloud\n",
    "np_pcd = np.asarray(pcd.points)\n",
    "ransac_n = 4 #点群から選択する点数は球だと4\n",
    "num_iterations = 1000 #RANSACの試行回数\n",
    "distance_th = 0.005 #モデルと点群の距離の閾値\n",
    "max_radius = 0.05 #検出する球の半径の最大値\n",
    "\n",
    "#初期化\n",
    "best_fitness = 0 #モデルの当てはめの良さ、インライア点数/全点数\n",
    "best_inlier_dist = 10000.0 #インライア点の平均距離\n",
    "best_inliers = None #元の点群におけるインライアのインデックス\n",
    "best_coeff = np.zeros(4) #モデルパラメータ\n",
    "\n",
    "for n in range(num_iterations):\n",
    "    c_id = np.random.choice(np_pcd.shape[0], 4, replace=False)\n",
    "    coeff = ComputerSphereCoefficient(\n",
    "                                    np_pcd[c_id[0]], np_pcd[c_id[1]], np_pcd[c_id[2]], np_pcd[c_id[3]])\n",
    "    if max_radius < coeff[3]:\n",
    "        continue\n",
    "    fitness, inlier_dist, inliers = EvaluateSphereCoefficient(np_pcd, coeff, distance_th)\n",
    "    if (best_fitness < fitness) or ((best_fitness == fitness) and (inlier_dist < best_inlier_dist)):\n",
    "        best_fitness = fitness\n",
    "        best_inlier_dist = inlier_dist\n",
    "        best_inliers = inliers\n",
    "        best_coeff = coeff\n",
    "        print(f\"Update: Fitness = {best_fitness:.4f}, Inlier_dist = {best_inlier_dist:.4f}\")\n",
    "        \n",
    "if best_coeff.any() != False:\n",
    "    print(f\"Sphere equation:  (x - {best_coeff[0]:.2f})^2 + (y - {best_coeff[1]:.2f})^2 + (z - {best_coeff[2]:.2f})^2) = {best_coeff[3]:.2f}^2\")\n",
    "else:\n",
    "    print(f\"No sphere detected.\")"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 45,
   "id": "82cbe9e4-b7e0-4378-acf2-e5c86c52116e",
   "metadata": {},
   "outputs": [],
   "source": [
    "#インライアを青に着色して可視化する\n",
    "sphere_cloud = pcd.select_by_index(best_inliers)\n",
    "sphere_cloud.paint_uniform_color([0, 0, 1.0])\n",
    "outlier_cloud = pcd.select_by_index(best_inliers, invert=True)\n",
    "o3d.visualization.draw_geometries([sphere_cloud, outlier_cloud])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 46,
   "id": "682e6006-e244-49d8-8bfa-de9fb36cd351",
   "metadata": {},
   "outputs": [],
   "source": [
    "#平面と球を同時に検出。そしてそれぞれを色で分ける\n",
    "mesh_sphere = o3d.geometry.TriangleMesh.create_sphere(radius=best_coeff[3])\n",
    "mesh_sphere.compute_vertex_normals()\n",
    "mesh_sphere.paint_uniform_color([0.3, 0.3, 0.7])\n",
    "mesh_sphere.translate(best_coeff[:3])\n",
    "o3d.visualization.draw_geometries([mesh_sphere] + [sphere_cloud+plane_cloud+outlier_cloud])"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "72e9ef24-d16b-4705-bbcc-a6fc9731643e",
   "metadata": {},
   "source": [
    "## 5.5 セグメンテーション"
   ]
  },
  {
   "cell_type": "markdown",
   "id": "fafa6478-6909-43f2-acfc-580385a1d800",
   "metadata": {},
   "source": [
    "- オーバーセグメンテーション　\n",
    "    - 認識したい物体より細かいパーツ単位でセグメンテーションすること\n",
    "- DBSCAN(Density Based Spatial Clustering of Applications with Noise)\n",
    "    - 点群データのオーバーセグメンテーション\n",
    "    - ２点間のユークリッド距離に基づいたクラスタリングを行う手法\n",
    "    - ２点間距離がある閾値以内である点同士を同じクラスタと認識し、それ以外を外れ値とする\n",
    "    - 全て点に対して、コア点か境界点か外れ値かのどれかで分ける\n",
    "        - これを繰り返す"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 50,
   "id": "782bf503-c07a-4768-8155-d886823a5ce1",
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "Loading a point cloud from ../3rdparty/Open3D/examples/test_data/fragment.pcd\n",
      "PointCloud with 113662 points.\n",
      "point cloud has 7 clusters\n",
      "\u001b[1;33m[Open3D WARNING] GLFW Error: Cocoa: Failed to find service port for display\u001b[0;m\n"
     ]
    }
   ],
   "source": [
    "import sys\n",
    "import open3d as o3d\n",
    "import numpy as np\n",
    "import matplotlib.pyplot as plt\n",
    "\n",
    "#filename = sys.argv[1]\n",
    "filename = \"../3rdparty/Open3D/examples/test_data/fragment.pcd\"\n",
    "print(\"Loading a point cloud from\", filename)\n",
    "pcd = o3d.io.read_point_cloud(filename)\n",
    "print(pcd)\n",
    "\n",
    "labels = np.array(pcd.cluster_dbscan(eps=0.02, min_points=10))\n",
    "\n",
    "max_label = labels.max()\n",
    "print(f\"point cloud has {max_label + 1} clusters\")\n",
    "colors = plt.get_cmap(\"tab20\")(labels / max(max_label, 1))\n",
    "colors[labels < 0] = 0\n",
    "pcd.colors = o3d.utility.Vector3dVector(colors[:, :3])\n",
    "o3d.visualization.draw_geometries([pcd], zoom=0.8,\n",
    "                                 front=[-0.04999, -0.1659, -0.8499],\n",
    "                                 lookat=[2.1813, 2.0619, 2.0999],\n",
    "                                 up=[0.1204, -0.9852, 0.1215])"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "id": "80ae2269-8b4a-4d7e-a92f-69dc4764ea90",
   "metadata": {},
   "outputs": [],
   "source": []
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.8.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 5
}
